{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed, BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import argparse, torch\n",
    "import pandas as pd\n",
    "import umap.umap_ as umap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "set_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='search for best template according to dev set')\n",
    "parser.add_argument('--max_len', default=512, type=int, help=\"max sequence length\")\n",
    "parser.add_argument('--batch_size', default=2, type=int, help=\"batch size\")\n",
    "parser.add_argument('--model', default='../models/my_bert/', type=str, help=\"pretrained model\")\n",
    "parser.add_argument('--tokenizer', default='../models/my_bert/', type=str, help=\"tokenizer\")\n",
    "parser.add_argument('--task', default='ecommerce', type=str, help=\"task name\")\n",
    "parser.add_argument('--datasets', default='../datasets_ppl_score/', type=str, help=\"dataset dir\")\n",
    "parser.add_argument('--template', default='很好。', type=str, help=\"template\")\n",
    "parser.add_argument('--input_data', default='../datasets/', type=str, help=\"input data dir\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(f'{args.tokenizer}')\n",
    "pretrained_model = BertModel.from_pretrained(args.model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_all = pd.read_csv(f'{args.input_data}{args.task}_output.csv',names=['labels','text'],header=0)\n",
    "texts = pd_all.text.tolist()\n",
    "labels = pd_all.labels.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = []\n",
    "with torch.no_grad():\n",
    "    for (text,label) in tqdm(zip(texts,labels)):\n",
    "        \n",
    "        # if label == 1:\n",
    "        #     text = '很满意。'+text\n",
    "        # else:\n",
    "        #     text = '不满意。'+text\n",
    "\n",
    "        # text = '[MASK]满意。'+text\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        outputs = pretrained_model(**inputs)\n",
    "\n",
    "        last_hidden_states = outputs.last_hidden_state.squeeze(0).mean(0)\n",
    "        text_embeddings.append(last_hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.stack(text_embeddings)\n",
    "norm_text_vectors = f.normalize(text_embeddings,p=2,dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize\n",
    "manifold = umap.UMAP(n_neighbors=15,min_dist=0.0,random_state = 2022).fit(norm_text_vectors)\n",
    "X_reduced_2 = manifold.transform(norm_text_vectors)\n",
    "\n",
    "# X_reduced_2 = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3,random_state=0).fit_transform(norm_text_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(['salmon','steelblue'])\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "scatter1 = ax.scatter(X_reduced_2[:][:, 0], X_reduced_2[:][:, 1], c=labels[:], s=20,cmap=cmap)\n",
    "legend1 = ax.legend(*scatter1.legend_elements(),prop={'size': 22})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Feb 24 2021, 21:46:12) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
